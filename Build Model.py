# -*- coding: utf-8 -*-
"""Coba sampel.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UiBCId_c3aUqrPTiJBj0tIwu21rPK_Xj
"""

# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error, r2_score, confusion_matrix, classification_report
from sklearn.neural_network import MLPRegressor
from keras.models import Sequential
from keras.layers import LSTM, Dense, Dropout
from keras.optimizers import Adam
from sklearn.model_selection import GridSearchCV
from keras.callbacks import EarlyStopping, ModelCheckpoint
from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import Pipeline
from tensorflow.keras.regularizers import l2
from sklearn.linear_model import Ridge
import joblib
from sklearn.neural_network import MLPRegressor
from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer

data = pd.read_csv('kliknklik_gaming_laptop.csv')
print(data.head())

print(data.info())
print(data.describe())

data.isna().sum()

# Data cleaning (optional)
data_cleaned = data.drop(columns=['Berat', 'Garansi', 'Dimensi', 'Keyboard', 'Microsoft Office'])
data_cleaned = data_cleaned.fillna(data_cleaned.mode().iloc[0])

# Hasil akhir
print(data_cleaned.head(100))

# Tambahkan kolom 'IPS' berdasarkan keberadaan kata 'IPS' di kolom 'Nama'
data_cleaned['IPS'] = data_cleaned['Nama'].apply(lambda x: 1 if 'IPS' in x.upper() else 0)

# Ubah kolom 'VGA' menjadi 'VGA Brand' dengan isinya hanya merek VGA saja
data_cleaned['VGA Brand'] = data_cleaned['VGA'].str.split().str[0]

# Hapus kolom 'VGA' karena sudah diganti dengan 'VGA Brand'
data_cleaned = data_cleaned.drop(columns=['VGA'])

# Hasil akhir
print(data_cleaned.head())

# Fungsi untuk mengonversi penyimpanan menjadi float dalam GB
def convert_storage(storage):
    if 'TB' in storage:
        return int(storage.replace('TB', '')) * 1000
    elif 'GB' in storage:
        return int(storage.replace('GB', ''))
    else:
        return 0

# Pisahkan 'Tipe Penyimpanan' menjadi kolom 'SSD' dan 'HDD'
data_cleaned['SSD'] = data_cleaned.apply(lambda x: convert_storage(x['Penyimpanan']) if x['Tipe Penyimpanan'] == 'SSD' else 0, axis=1)
data_cleaned['HDD'] = data_cleaned.apply(lambda x: convert_storage(x['Penyimpanan']) if x['Tipe Penyimpanan'] == 'HDD' else 0, axis=1)

# Hapus kolom 'Tipe Penyimpanan' dan 'Penyimpanan' karena sudah dipisah
data_cleaned = data_cleaned.drop(columns=['Tipe Penyimpanan', 'Penyimpanan'])

# Ubah nama kolom 'Tipe Layar' menjadi 'Touchscreen' dan beri nilai 1 jika touchscreen, 0 jika non-touchscreen
data_cleaned.rename(columns={'Tipe Layar': 'Touchscreen'}, inplace=True)
data_cleaned['Touchscreen'] = data_cleaned['Touchscreen'].apply(lambda x: 1 if x.lower() == 'touchscreen' else 0)

print(data_cleaned.head())

data_cleaned['Ukuran Layar'] = data_cleaned['Ukuran Layar'].replace('[^\d]', '', regex=True).astype(float)
data_cleaned['RAM'] = data_cleaned['RAM'].replace('[^\d]', '', regex=True).astype(int)
data_cleaned['Harga'] = data_cleaned['Harga'].replace('[^\d]', '', regex=True).astype(float)

print(data_cleaned.head(100))

print(data_cleaned.info())

#cek unique value setiap kolom
for column in data_cleaned.columns:
    # Mencetak nama kolom
    print(f"Column: {column}")

    # Mencetak nilai unik dari kolom tersebut
    unique_values = data_cleaned[column].unique()
    print(unique_values)

    # Jarak antar kolom
    print("-"*30)

# Pisahkan variabel independen (X) dan dependen (y)
X = data_cleaned.drop(columns=['Harga'])
y = data_cleaned['Harga']

# Split data menjadi data latih dan data uji
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=2)

# Tampilkan informasi tentang pembagian data
print("Data latih:", X_train.shape, y_train.shape)
print("Data uji:", X_test.shape, y_test.shape)

# Tampilkan isi data variabel X dan y
print("Isi variabel X:")
print(X.head())  # Menampilkan 5 baris pertama dari X

print("\nIsi variabel y:")
print(y.head())  # Menampilkan 5 baris pertama dari y

# Identify categorical and numerical columns
categorical_columns = X.select_dtypes(include=['object']).columns
numerical_columns = X.select_dtypes(include=['int64', 'float64']).columns

# Define the preprocessing steps
preprocessor = ColumnTransformer(
    transformers=[
        ('cat', OneHotEncoder(sparse_output=False, drop='first', handle_unknown='ignore'), categorical_columns),
        ('num', StandardScaler(), numerical_columns)
    ]
)

# Apply transformations to training data
X_train_transformed = preprocessor.fit_transform(X_train)
X_test_transformed = preprocessor.transform(X_test)

# Scale target variable
scaler_y = MinMaxScaler()
y_train_transformed = scaler_y.fit_transform(y_train.values.reshape(-1, 1))
y_test_transformed = scaler_y.transform(y_test.values.reshape(-1, 1))

# Reshape for LSTM input
X_train_lstm = X_train_transformed.reshape((X_train_transformed.shape[0], 1, X_train_transformed.shape[1]))
X_test_lstm = X_test_transformed.reshape((X_test_transformed.shape[0], 1, X_test_transformed.shape[1]))

# Stacked LSTM Model
def build_stacked_lstm(input_shape):
    model = Sequential()
    model.add(LSTM(64, return_sequences=True, input_shape=input_shape))
    model.add(Dropout(0.3))
    model.add(LSTM(64, return_sequences=False))
    model.add(Dropout(0.3))
    model.add(Dense(1, kernel_regularizer=l2(0.01)))
    model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')
    return model

stacked_lstm_model = build_stacked_lstm((X_train_lstm.shape[1], X_train_lstm.shape[2]))
early_stopping = EarlyStopping(patience=5, restore_best_weights=True)
history = stacked_lstm_model.fit(
    X_train_lstm,
    y_train_transformed,
    epochs=50,
    batch_size=32,
    validation_data=(X_test_lstm, y_test_transformed),
    callbacks=[early_stopping],
    verbose=1
)

# Visualisasi untuk Model LSTM
plt.figure(figsize=(8, 6))
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('LSTM Model Training and Validation Loss')
plt.legend()
plt.show()

# Evaluate models
stacked_lstm_predictions = stacked_lstm_model.predict(X_test_lstm)

stacked_lstm_mse = mean_squared_error(y_test_transformed, stacked_lstm_predictions)
stacked_lstm_rmse = np.sqrt(stacked_lstm_mse)
stacked_lstm_r2 = r2_score(y_test_transformed, stacked_lstm_predictions)

print("Stacked LSTM Model Evaluation:")
print(f"Mean Squared Error (MSE): {stacked_lstm_mse}")
print(f"Root Mean Squared Error (RMSE): {stacked_lstm_rmse}")
print(f"R2 Score: {stacked_lstm_r2}")

# Visualisasi untuk Model LSTM (Actual vs Predicted)
plt.figure(figsize=(8, 6))
scaled_predictions = scaler_y.inverse_transform(stacked_lstm_predictions)
plt.scatter(y_test, scaled_predictions, alpha=0.5, label='LSTM')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)
plt.xlabel('Actual')
plt.ylabel('Predicted')
plt.title('LSTM Model: Actual vs Predicted')
plt.legend()
plt.show()

print("Hasil Transformasi Data Latih:")
print(X_train_transformed[:5])  # Menampilkan 5 baris pertama data latih

print("\nHasil Transformasi Data Uji:")
print(X_test_transformed[:5])  # Menampilkan 5 baris pertama data uji

print("Hasil Transformasi Target Data Latih:")
print(y_train_transformed[:5])  # Menampilkan 5 nilai pertama target data latih

print("\nHasil Transformasi Target Data Uji:")
print(y_test_transformed[:5])  # Menampilkan 5 nilai pertama target data uji

# Define pipeline for Linear Regression
pipe_lr = Pipeline([
    ('preprocessor', preprocessor),
    ('regressor', LinearRegression())
])

# Fit pipeline ke data latih
pipe_lr.fit(X_train, y_train)

# Predict pada data uji
y_pred_lr = pipe_lr.predict(X_test)

# Evaluasi model Linear Regression
mse_lr = mean_squared_error(y_test, y_pred_lr)
rmse_lr = np.sqrt(mse_lr)
r2_lr = r2_score(y_test, y_pred_lr)

# Cetak hasil evaluasi
print("\nLinear Regression Model Evaluation:")
print(f"Mean Squared Error (MSE): {mse_lr:.4f}")
print(f"Root Mean Squared Error (RMSE): {rmse_lr:.4f}")
print(f"R2 Score: {r2_lr:.4f}")

# Visualisasi untuk Model Linear Regression
plt.figure(figsize=(8, 6))
plt.scatter(y_test, y_pred_lr, alpha=0.5, label='Linear Regression')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)
plt.xlabel('Actual')
plt.ylabel('Predicted')
plt.title('Linear Regression: Actual vs Predicted')
plt.legend()
plt.show()

# Define the pipeline for Ridge Regression
pipe_ridge = Pipeline([
    ('preprocessor', preprocessor),
    ('regressor', Ridge())
])

# Log-transform target variable for Ridge Regression to handle skewness
y_train_log = np.log1p(y_train)
y_test_log = np.log1p(y_test)

# Set up hyperparameter tuning for Ridge
param_grid = {
    'regressor__alpha': [0.01, 0.1, 1, 10]
}

# Use GridSearchCV for Ridge hyperparameter tuning
ridge_search = GridSearchCV(pipe_ridge, param_grid, cv=5, scoring='r2', n_jobs=-1)
ridge_search.fit(X_train, y_train_log)

# Best model and its parameters
best_ridge_model = ridge_search.best_estimator_
best_alpha = ridge_search.best_params_['regressor__alpha']
print(f"Best alpha for Ridge: {best_alpha}")

# Predict on test data
y_pred_ridge_log = best_ridge_model.predict(X_test)

# Reverse the log transformation
y_pred_ridge = np.expm1(y_pred_ridge_log)

# Evaluate the Ridge Regression model
mse_ridge = mean_squared_error(y_test, y_pred_ridge)
rmse_ridge = np.sqrt(mse_ridge)
r2_ridge = r2_score(y_test, y_pred_ridge)

# Print evaluation results
print("\nRidge Regression Model Evaluation:")
print(f"Mean Squared Error (MSE): {mse_ridge:.4f}")
print(f"Root Mean Squared Error (RMSE): {rmse_ridge:.4f}")
print(f"R2 Score: {r2_ridge:.4f}")

# Visualisasi untuk Model Ridge Regression
plt.figure(figsize=(8, 6))
plt.scatter(y_test, y_pred_ridge, alpha=0.5, label='Ridge Regression')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)
plt.xlabel('Actual')
plt.ylabel('Predicted')
plt.title('Ridge Regression: Actual vs Predicted')
plt.legend()
plt.show()

from sklearn.neural_network import MLPRegressor
from sklearn.model_selection import GridSearchCV

# Define the MLP pipeline
mlp_pipeline = Pipeline([
    ('preprocessor', preprocessor),  # Menggunakan preprocessor yang sama
    ('mlp', MLPRegressor(
        max_iter=500,         # Maksimum iterasi default
        random_state=2       # Untuk memastikan hasil replikasi
    ))
])

# Hyperparameter tuning untuk MLP
param_grid_mlp = {
    'mlp__hidden_layer_sizes': [(128, 64, 32), (64, 32), (100, 50)],
    'mlp__activation': ['relu', 'tanh'],
    'mlp__solver': ['adam', 'lbfgs'],
    'mlp__alpha': [0.0001, 0.001, 0.01, 0.1, 1.0],  # Regularization term
    'mlp__learning_rate': ['constant', 'adaptive']
}

# Gunakan GridSearchCV untuk mencari hyperparameter terbaik
mlp_search = GridSearchCV(mlp_pipeline, param_grid_mlp, cv=5, scoring='r2', n_jobs=-1, verbose=2)
mlp_search.fit(X_train, y_train_log)

# Model MLP terbaik setelah tuning
best_mlp_model = mlp_search.best_estimator_
best_params_mlp = mlp_search.best_params_
print("\nBest hyperparameters for MLP:")
print(best_params_mlp)

# Predict using the best MLP model
y_pred_mlp_log = best_mlp_model.predict(X_test)

# Reverse log transformation
y_pred_mlp = np.expm1(y_pred_mlp_log)

# Evaluate the MLP model
rmse_mlp = np.sqrt(mean_squared_error(y_test, y_pred_mlp))
mse_mlp = mean_squared_error(y_test, y_pred_mlp)
r2_mlp = r2_score(y_test, y_pred_mlp)

# Print evaluation results
print("\nMulti-layer Perceptron Model Evaluation:")
print(f"Root Mean Squared Error (RMSE): {rmse_mlp:.4f}")
print(f"Mean Squared Error (MSE): {mse_mlp:.4f}")
print(f"R-squared (R2): {r2_mlp:.4f}")

# Visualisasi untuk Model MLP
plt.figure(figsize=(8, 6))
plt.scatter(y_test, y_pred_mlp, alpha=0.5, label='MLP')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)
plt.xlabel('Actual')
plt.ylabel('Predicted')
plt.title('MLP Model: Actual vs Predicted')
plt.legend()
plt.show()

# Visualize Results
plt.figure(figsize=(10, 6))
plt.plot(y_test.values[:50], label='Actual', marker='o', color='black')
plt.plot(scaled_predictions[:50], label='LSTM Predictions', marker='o', color='blue')
plt.plot(y_pred_ridge[:50], label='Ridge Predictions', marker='o', color='green')
plt.plot(y_pred_mlp[:50], label='MLP Predictions', marker='o', color='red')
plt.title('Model Predictions vs Actual (First 50 Samples)')
plt.xlabel('Sample Index')
plt.ylabel('Price')
plt.legend()
plt.tight_layout()
plt.show()

# Pilih 5 sampel data secara acak
sample_data = data_cleaned.sample(5, random_state=13)  # Pilih 5 baris data secara acak
print("Data Sampel:")
print(sample_data)

# Pisahkan variabel independen dan dependen pada data sampel
X_sample = sample_data.drop(columns=['Harga'])
y_sample = sample_data['Harga']

# Pra-pemrosesan data sampel
X_sample_transformed = preprocessor.transform(X_sample)

# Reshape data sampel untuk input ke LSTM
X_sample_lstm = X_sample_transformed.reshape((X_sample_transformed.shape[0], 1, X_sample_transformed.shape[1]))

# Prediksi menggunakan model LSTM
sample_predictions_scaled = stacked_lstm_model.predict(X_sample_lstm)

# Kembalikan skala prediksi ke harga asli
sample_predictions = scaler_y.inverse_transform(sample_predictions_scaled)

# Tampilkan hasil prediksi
print("\nHasil Prediksi:")
for i in range(len(sample_data)):
    print(f"Sampel {i+1}:")
    print(f"Harga Asli: {y_sample.iloc[i]:,.2f}")
    print(f"Harga Prediksi: {sample_predictions[i][0]:,.2f}")
    print("-" * 30)